{"cells":[{"cell_type":"code","source":["#@title Install Dependencies\n","! pip uninstall -y openai\n","! pip install openai==0.28\n","! pip install git+https://github.com/Quick-Pass/aipot/tree/main/chap04/automatic-prompt-engineer"],"metadata":{"id":"x82vwepAs3Jg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","openai.api_key = 'Open AI에서 API키를 발급받아서 입력한다.'"],"metadata":{"id":"HbYuP9fSwDUb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7W5nQxnZsyS1"},"source":["# Optimizing Prompts with **Automatic Prompt Engineer** (APE)\n","\n","This notebook demonstrates how to use Automatic Prompt Engineer (APE) (arxiv link) to optimize prompts for text generation. In its simplest form, APE takes as input a dataset (a list of inputs and a list of outputs), a prompt template, and optimizes this prompt template so that it generates the outputs given the inputs.\n","\n","APE accomplishes this in two steps. First, it uses a language model to generate a set of candidate prompts. Then, it uses a prompt evaluation function to evaluate the quality of each candidate prompt. Finally, it returns the prompt with the highest evaluation score."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbAA6kE5syS5"},"outputs":[],"source":["# First, let's define a simple dataset consisting of words and their antonyms.\n","words = [\"sane\", \"direct\", \"informally\", \"unpopular\", \"subtractive\", \"nonresidential\",\n","    \"inexact\", \"uptown\", \"incomparable\", \"powerful\", \"gaseous\", \"evenly\", \"formality\",\n","    \"deliberately\", \"off\"]\n","antonyms = [\"insane\", \"indirect\", \"formally\", \"popular\", \"additive\", \"residential\",\n","    \"exact\", \"downtown\", \"comparable\", \"powerless\", \"solid\", \"unevenly\", \"informality\",\n","    \"accidentally\", \"on\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUxGByFssyS6"},"outputs":[],"source":["# Now, we need to define the format of the prompt that we are using.\n","\n","eval_template = \\\n","\"\"\"Instruction: [PROMPT]\n","Input: [INPUT]\n","Output: [OUTPUT]\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DX06_wgsyS7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708004142285,"user_tz":-540,"elapsed":32954,"user":{"displayName":"Ho Yong Lim","userId":"08980650706261585781"}},"outputId":"06f0a8aa-9a8f-4d35-d902-1d4e25965eec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating prompts...\n","[GPT_forward] Generating 20 completions, split into 1 batches of size 2000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model returned 20 prompts. Deduplicating...\n","Deduplicated to 20 prompts.\n","Evaluating prompts...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating prompts: 100%|██████████| 50/50 [00:31<00:00,  1.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Finished evaluating.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Now, let's use APE to find prompts that generate antonyms for each word.\n","from automatic_prompt_engineer import ape\n","\n","result, demo_fn = ape.simple_ape(\n","    dataset=(words, antonyms),\n","    eval_template=eval_template,\n","    eval_model='davinci-002',\n","    prompt_gen_model='davinci-002',\n","    num_prompts=20,\n","    eval_rounds=50,\n","    prompt_gen_batch_size=200,\n","    eval_batch_size=500\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YXHoK_4esyS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708004258994,"user_tz":-540,"elapsed":321,"user":{"displayName":"Ho Yong Lim","userId":"08980650706261585781"}},"outputId":"30f20bca-7b51-46a7-ab18-e6b1caaad345"},"outputs":[{"output_type":"stream","name":"stdout","text":["score: prompt\n","----------------\n","-1.30:  find an algorithm, preferably a linear time one, to derive the output from the input.\n","\n","Can you derive an algorithm to do that?\n","\n","     \n","\n","From a friend's comment on FB: \"Maybe because I always tell my kids to take the opposite of what\n","-1.59:  derive:\n","\n","Input: insane\n","Output: sanely\n","\n","How would you approach the instruction?\n","Callou-2-3-5: Draw a tree with, at each node, two children: \"downtown\" and \"uptown\". (\n","-2.15:  make the output come from the input (an indirect mapping), but I have no idea how to solve it.\n","\n","Now I have a feeling that this is too simple of a question, but it still stumps me. If anyone knows of an algorithm to\n","-2.44:  consider any input and output in the pair as separate words (note: only the first letter is capitalised), and construct an analogy between the first two words in the pair and the last two words in the pair. So the instruction given to my friend\n","-2.46:  match the input with the correct output. The friend didn’t know what the instruction was. A few months later they tried to remember what the instruction was and tried to re-do the same exercise. To their horror they couldn’t match any of the inputs\n","-2.73:  replace the first word in each input with the second word in each output.\n","\n","My friend got very, very, very mad at me and called me a *%$@$%& idiot.\n","\n","Then I tried to explain that he had done exactly what I\n","-2.97:  map \"direct\" to \"indirect\" and so on. If you knew the instruction what would you guess the output for the following inputs:\n","\n","- residential\n","- residential\n","- uptown\n","- solid\n","- uptown\n","- downtown\n","\n","It\n","-3.04:  type an error in the first input and get an error in the output. They concluded that there was an error in my input-output pairs. I concluded that their input-output pairs were erroneous. Who was right?\n","\n","More Context\n","\n","The instructions I gave to\n","-3.12:  flip the direct/indirect pair. My friend was unable to do this, because in the new inputs, the concepts can't be paired with the new outputs. This is the challenge we're facing in evolving natural language.\n","\n","Let's say your friend\n","-3.47:  produce a table for the following:\n","\n","Input: (any) Output: (any)\n","\n","Because of the above pairs it is clear that the following cannot be correct:\n","\n","Input: direct Output: nonresidential\n","\n","Note: The output for 'direct' is\n","\n"]}],"source":["# Let's see the results.\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"7PE_bMX2syS9"},"source":["Let's compare with a prompt written by a human:\n","\n","\"*Write an antonym to the following word.*\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXkvmnXrsyS9"},"outputs":[],"source":["from automatic_prompt_engineer import ape\n","\n","manual_prompt = \"Write an antonym to the following word.\"\n","\n","human_result = ape.simple_eval(\n","    dataset=(words, antonyms),\n","    eval_template=eval_template,\n","    prompts=[manual_prompt],\n","    eval_model='davinci-002',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elGm3qs3syS-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708004375194,"user_tz":-540,"elapsed":495,"user":{"displayName":"Ho Yong Lim","userId":"08980650706261585781"}},"outputId":"a2df0da5-31a1-4b76-b718-abeab01e24be"},"outputs":[{"output_type":"stream","name":"stdout","text":["log(p): prompt\n","----------------\n","-0.55: Write an antonym to the following word.\n","\n"]}],"source":["print(human_result)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"c2afcb7a2e6fcb9490d448e607abf9226c3f7acca28baeea9bc24b456562037f"}},"colab":{"provenance":[{"file_id":"1Hrz6Q7GFdH5OVg3Dis86f5OqiGdkDfRP","timestamp":1707926427373}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}